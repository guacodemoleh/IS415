---
title: "In-class Exercise 7"
author: "Victoria Grace ANN"
execute: 
  warning: false
  eval: true
  echo: true
  freeze: true
format:  
  html: 
    code-summary: "Show the code"
    toc-depth: 4
date: "4 March, 2024"
date-modified: "last-modified"
editor: visual
---

# Loading R packagess

```{r}
pacman::p_load(sp,spdep, tmap, sf, ClustGeo, 
               ggpubr, cluster, factoextra, NbClust,
               heatmaply, corrplot, psych, tidyverse, GGally)
```

-   GDAL is no longer in use, thus replaced with **sp**


# Importing data

Using *filter* **dplyr** function to select Shan state data,

```{r}
shan_sf <- st_read(dsn = "data/geospatial", 
                   layer = "myanmar_township_boundaries") %>%
  filter(ST %in% c("Shan (East)", "Shan (North)", "Shan (South)")) %>%
  select(c(2:7))
```

-   The data is filtering for all the Shan state regions.

```{r}
ict <- read_csv("data/aspatial/Shan-ICT.csv")
```


```{r}
shan_sf
```


```{r}
ict_derived <- ict %>%
  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %>%
  mutate(`TV_PR` = `Television`/`Total households`*1000) %>%
  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %>%
  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %>%
  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %>%
  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %>%
  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,
         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,
         `TT_HOUSEHOLDS`=`Total households`,
         `RADIO`=`Radio`, `TV`=`Television`, 
         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,
         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) 
```

-   The *rename* function enables the column names to be shorter and refined


# Visulisations

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```


```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO`)) +
  geom_boxplot(color="black", 
               fill="light blue")
```


```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```


```{r}
radio <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

tv <- ggplot(data=ict_derived, 
             aes(x= `TV_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

llphone <- ggplot(data=ict_derived, 
             aes(x= `LLPHONE_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

mphone <- ggplot(data=ict_derived, 
             aes(x= `MPHONE_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

computer <- ggplot(data=ict_derived, 
             aes(x= `COMPUTER_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

internet <- ggplot(data=ict_derived, 
             aes(x= `INTERNET_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

ggarrange(radio, tv, llphone, mphone, computer, internet, 
          ncol = 3, 
          nrow = 2)
```

-   *ggarrange* to define the order of the histograms.


```{r}
shan_sf <- left_join(shan_sf, 
                     ict_derived, by=c("TS_PCODE"="TS_PCODE"))
  
write_rds(shan_sf, "data/rds/shan_sf.rds")
```

-   the first argument of the *left_join()* should be a sf object

-   note that *st_join()* requires both data to be spatial


# Correlation Analysis

```{r}
cluster_vars.cor = cor(ict_derived[,12:17])
corrplot.mixed(cluster_vars.cor,
         lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
          tl.col = "black")
```


# Extracting clustering variables

```{r}
cluster_vars <- shan_sf %>%
  st_set_geometry(NULL) %>%
  select("TS.x", "RADIO_PR", "TV_PR", "LLPHONE_PR", "MPHONE_PR", "COMPUTER_PR")
head(cluster_vars,10)
```

-   *st_set_geometry(NULL)* needs to be used so that the resulting cluster data can remain as a traditional dataset with no geometry attribute.


Change the rows by township name rather than row number for easier referencing.

```{r}
n_distinct(cluster_vars$TS.x)
```

```{r}
row.names(cluster_vars) <- cluster_vars$"TS.x"
head(cluster_vars,10)
```

The first column can be excluded from our focus since the township name is captured in the row name.

```{r}
shan_ict <- select(cluster_vars, c(2:6))
head(shan_ict, 10)
```


# Min-Max standardisation

```{r}
shan_ict.std <- normalize(shan_ict)
summary(shan_ict.std)
```


# Computing Proximity Matrix

The *dist()* function supports six distance proximity calculations: - euclidean (default) - maximum - minimum - canberra - binary - minkowski

```{r}
proxmat <- dist(shan_ict, method = 'euclidean')
```

```{r echo=TRUE, eval=FALSE}
proxmat
```


# Computing Hierarchical Clustering

*hclust()* employs an agglomeration method to compute the cluster. The eight clustering algorithms supported ward.D, ward.D2, single, complete, average (UPGMA), mcquitty (WPGMA), median (WPGMC) and centroid (UPGMC).

To try hierarchical cluster analysis using the ward.D method,

```{r}
hclust_ward <- hclust(proxmat, method = 'ward.D')
```

-   the data must be a dissimilairty structure produced by `dist`


Plot the tree using *plot()*.

```{r}
plot(hclust_ward, cex = 0.6)
```

::: callout-note
# How to read dendogram
-   Use a height value as the cut-off
-   From there, you should be able to identify the number of clusters at that cut-off value
:::


# Determining Optimal Clusters

The common methods to determine the optimal clusters are: - Gap Statistic Method - Elbow Method - Average Silhouette Method

##
Gap Statistic Method

The gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.

To compute the gap statistic, clusGap() of cluster package will be used.

```{r}
set.seed(12345)
gap_stat <- clusGap(shan_ict, 
                    FUN = hcut, 
                    nstart = 25, 
                    K.max = 10, 
                    B = 50)
# Print the result
print(gap_stat, method = "firstmax")
```



::: callout-note
*hcut* is from the **factoextra** package.
:::

Visualise the plot using *fviz_gap_stat()* of the **factoextra** package.

```{r}
fviz_gap_stat(gap_stat)
```

-   The optimisation is local.
-   6 is the optimal number of clusters since it is the first peak.


# Interpreting Dendrograms

Each leaf in a dendrogram corresponds to one observation. Observations similar to each other are combined into branches as shown by tracing the dendrogram from bottom to top.

The **height** of these fused branches indicates the (dis)similarity between two observations. The higher these fusions, the less similar the observations.

To draw the dendogram with a border around the selected clusters using *rect.hclust()*, the argument `border` is used to specify the border colours of the rectangles.

```{r}
plot(hclust_ward, cex = 0.6)
rect.hclust(hclust_ward, 
            k = 6, 
            border = 2:5)
```


# Mapping Formed Clusters

Use *cutree()* to derive a 6-cluster model.

```{r}
groups <- as.factor(cutree(hclust_ward, k=6))
```

```{r}
shan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%
  rename(`CLUSTER`=`as.matrix.groups.`)
```
-   *cbind* can be used to append `groups` to `shan_sf`. This is because the order of the rows did not change. However, if there is sorting done, then doing this method is not appropriate.


Have a look at where are the clusters using a choropleth map.

```{r}
qtm(shan_sf_cluster, "CLUSTER")
```

# Computing Neighbour List

From a previous exercise, apply *poly2nb()* to compute the neighbours list for all the polygons.

```{r}
shan.nb <- poly2nb(shan_sf)
summary(shan.nb)
```

-   Now *poly2nb()* can read sf files!


Since our data is in sf, we need to get the centroid for each township so that we get our point object

```{r}
plot(st_geometry(shan_sf), 
     border=grey(.5))

pts <- st_coordinates(st_centroid(shan_sf))
plot(shan.nb, 
     pts, 
     col="blue", 
     add=TRUE)
```

-   *st_geometry()* helps to generate just one map polygon!


# Computing MST

```{r}
plot(st_geometry(shan_sf), 
     border=gray(.5))

lcosts <- nbcosts(shan.nb, shan_ict)
shan.w <- nb2listw(shan.nb, 
                   lcosts, 
                   style="B")
shan.mst <- mstree(shan.w)

plot.mst(shan.mst, 
         pts, 
         col="blue", 
         cex.lab=0.7, 
         cex.circles=0.005, 
         add=TRUE)
```


# Ward-like hierarchical clustering: ClustGeo

Typically, *hclustgeo()* performs Ward-like hierarchical clustering like what *hclust()* does.

To perform non-spatially constrained hierarchical clustering, we only need to pass a dissimilarity matrix in the function.

```{r}
nongeo_cluster <- hclustgeo(proxmat)
plot(nongeo_cluster, cex = 0.5)
rect.hclust(nongeo_cluster, 
            k = 6, 
            border = 2:5)
```

# Mapping the formed clusters

```{r}
groups <- as.factor(cutree(nongeo_cluster, k=6))

shan_sf_ngeo_cluster <- cbind(shan_sf, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)

qtm(shan_sf_ngeo_cluster, "CLUSTER")
```


# Multivariate Visualisation

Past studies shown that parallel coordinate plot can be used to reveal clustering variables by cluster very effectively. In the code chunk below, ggparcoord() of GGally package

```{r}
ggparcoord(data = shan_sf_ngeo_cluster, 
           columns = c(17:21), 
           scale = "globalminmax",
           alphaLines = 0.2,
           boxplot = TRUE, 
           title = "Multiple Parallel Coordinates Plots of ICT Variables by Cluster") +
  facet_grid(~ CLUSTER) + 
  theme(axis.text.x = element_text(angle = 30))
```

Cluster 5 has the lowest ownership of ICTs.
