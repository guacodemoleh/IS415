---
title: "In-class Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR"
author: "Victoria Grace ANN"
execute: 
  warning: false
date: "11 March, 2024"
date-modified: "last-modified"
---

# Overview

**Geographically weighted regression (GWR)** is a spatial statistical technique that considers non-stationary variables, including but not withstanding climate, demographic factors, and physical environment characteristics. GWR also models local relationships between these independent variables and the outcome of interest, i.e. dependent variable.

This exercise is working on building hedonic pricing models using GWR methods. The dependent variable is the condominium resale prices in 2015, and the independent variables are divided in to either structural and locational.

# Data used

-   Geospatial: MP14_SUBZONE_WEB_PL
-   Aspatial: condo_resale_2015.csv

# Set-up

The following R packages need to be installed before beginning the exercise.

1\. Ordinary Least Squares - olsrr <a href="https://olsrr.rsquaredacademy.com/"></a>

2\. Geographical Weighted Model - GWmodel <a href="https://cran.r-project.org/web/packages/GWmodel/"></a>

3\. Multivariate data visualisation and analysis - corrplot <a href="https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html"></a>, ggstatplot

4\. Spatial data handling - **sf**

5\. Attribute data handling - **tidyverse**, particularly **readr**, **ggplot2**, **dplyr**

6\. Choropleth mapping - **tmap**

```{r}
pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary, ggstatsplot)
```

# Geospatial Data Wrangling

## Importing geospatial data

```{r}
mpsz = st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

## Updating CRS information

```{r}
mpsz_svy21 <- st_transform(mpsz, 3414)
```

Verify the transformed CRS

```{r}
st_crs(mpsz_svy21)
```

Reveal coordinate extenets of *mpsz_svy21* by using *st_bbox()* of the **sf** package.

```{r}
st_bbox(mpsz_svy21) #view extent
```

# Aspatial Data Wrangling

## Importing aspatial data

```{r}
condo_resale = read_csv("data/aspatial/condo_resale_2015.csv")
```

Understand the data structure using *glimpse()*

```{r}
glimpse(condo_resale)
```

```{r}
head(condo_resale$LONGITUDE) #see the data in XCOORD column
```

```{r}
head(condo_resale$LATITUDE) #see the data in YCOORD column
```

Statistics summary.

```{r}
summary(condo_resale)
```

## Converting aspatial data frame into a sf object

Use *st_as_sf()*

```{r}
condo_resale.sf <- st_as_sf(condo_resale,
                            coords = c("LONGITUDE", "LATITUDE"),
                            crs=4326) %>%
  st_transform(crs=3414)
```

-   \*st_transform() is used to convert the coordinates from wgs84 to svy21

```{r}
head(condo_resale.sf)
```

# Exploratory Data Analysis

This section focuses on using statistical graphic functions of the **ggplot2** package to perform EDA.

## EDA using statistical graphics

Distribution of selling price

```{r}
ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

-   There is a right-skewed distribution of the selling price, indicating that more condominium units were sold at lower prices.

The skewed distribution can be normalised by using log transformation. A new variable *LOG_SELLING_PRICE* can contain the transformed selling prices. The transformation is performed using **dplyr**'s *mutate()*.

```{r}
condo_resale.sf <- condo_resale.sf %>%
  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))
```

Plotting *LOG_SELLING_PRICE*

```{r}
ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

## Multiple Histogram Plots distribution

Small multiple histograms, or trellis plots, are drawn using *ggarrange()* in the **ggpubr** package.

The code chunk below is used to create 12 histograms. *ggarrange()* is used to organise these histograms into a 3-columns by-4-rows small multiple plot.

```{r}
AREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + 
  geom_histogram(bins=20, color="black", fill="light blue")

AGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + 
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_URA_GROWTH_AREA`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, 
          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,
          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  
          ncol = 3, nrow = 4)
```

## Drawing Statistical Point Map

Using **tmap**, we can reveal the geospatial distribution of the condominium resale prices in Singapore.

Turning on the interactive mode of tmap,

```{r}
tmap_mode("view")
```

```{r}
tmap_mode("plot")
```

Creating an interactive point symbol map,

```{r}
tm_shape(mpsz_svy21)+
  tm_polygons() +
tm_shape(condo_resale.sf) +  
  tm_dots(col = "SELLING_PRICE",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))

```

-   *tm_dots()* is used instead of *tm_bubbles*

*set.zoom.limits* argument of *tm_view()* sets the minimum and maximum zoom level to 11 and 14 respectively.

Now turn the R display into *plot* mode.

```{r}
tmap_mode("plot")
```

# Hedonic Pricing Modelling in R

This section focuses on building hedonic pricing models for condominium resale units using *lm()* of R base.

## Simple Linear Regression Method

Build a simple linear regression model using *SELLING_PRICE* as the dependent variable and *AREA_SQM* as the independent variable.

```{r}
condo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)
```

-   *lm()* returns an object of class *lm* or for multiple responses of class c("mlm", "lm").

The functions *summary* and *anova()* can be used to obtain and print a summasry and analysis of variance tables of the results. The generic accessor functions coefficients, effevts, fitted.values and residuals extract various useful features of the value returned by *lm*.

```{r}
summary(condo.slr)
```

Looking at the summary statistic, *SELLING_PRICE*, y, can be explained as:

$$
y = -258121.1 + 14719x_{1}
$$ The R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.

Since p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.

The **Coefficients:** section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.

The best fit curve can be visualised using *lm()* as a method function in ggplot's geometry as shown in the code chunk below.

```{r}
ggplot(data=condo_resale.sf,  
       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +
  geom_point() +
  geom_smooth(method = lm)
```

-   The figure above reveals that there are a few statistical outliers with relatively high selling prices.

## Multiple Linear Regression Method

### Visualising relationships between independent variables

In order to build a more reliable multiple regression model, it is important to verify that the independent variables are not highly correlated to one another, i.e. multicolinearity. Otherwise, the quality of the model will be compromised.

A correlation matrix is commonly used to visualise the relationships between the independent variables. Beside the *pairs()* in R, there are many packages supporting the display of correlation matrices. In this section, the corrplot package will be used.

The code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in the *condo_resale* data frame.

```{r}
corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")
```

```{r}
ggcorrmat(condo_resale[,5:23])
```

Matrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used.

From the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.

## Building a hedonic pricing model using multiple linear regression

Using *lm()* to calibrate the multiple linear regression model

```{r}
condo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + 
                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + 
                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + 
                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + 
                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                data=condo_resale.sf)
summary(condo.mlr)
```

## Preparing Publication Quality Table

### Using olsrr

Not all the independent variables are statistically significant. The model can be revised by removing the variables that are not statisically significant.

Calibrate the revised model using the following code chunk,

```{r}
condo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + 
                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + 
                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,
                 data=condo_resale.sf)
ols_regress(condo.mlr1)
```

### using gtsummary

The gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R

The following code chunk shows how *tbl_regression* is used to create a well-formatted regression report.

```{r}
tbl_regression(condo.mlr1, intercept = TRUE)
```

With gtsummary package, model statistics can be included in the report by either appending them to the report table by using *add_glance_table()* or adding as a table source note by using *add_glance_source_note()*.

```{r}
tbl_regression(condo.mlr1, 
               intercept = TRUE) %>% 
  add_glance_source_note(
    label = list(sigma ~ "\U03C3"),
    include = c(r.squared, adj.r.squared, 
                AIC, statistic,
                p.value, sigma))
```

#### Checking for multicolinearity

```{r}
ols_vif_tol(condo.mlr1)
```

##### Visualising

```{r}
ggcoefstats(condo.mlr1)
```

-   Such a graph is useful for a generic interpretation of all the confidence of each variable.

#### Test for Non-linearity

```{r}
ols_plot_resid_fit(condo.mlr1)
```

The figure above reveals that most of the data points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.

### Test for Normality Assumption

```{r}
ols_plot_resid_hist(condo.mlr1)
```

The figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.

If you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.

```{r}
ols_test_normality(condo.mlr1)
```

The summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.

## Testing for Spatial Autocorrelation

The hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.

In order to perform spatial autocorrelation test, we need to convert *condo_resale.sf* from sf data frame into a **SpatialPointsDataFrame**.

First, we will export the residual of the hedonic pricing model and save it as a data frame.

```{r}
mlr.output <- as.data.frame(condo.mlr1$residuals)
```

Next, we will join the newly created data frame with *condo_resale.sf* object.

```{r}
condo_resale.res.sf <- cbind(condo_resale.sf, 
                        condo.mlr1$residuals) %>%
rename(`MLR_RES` = `condo.mlr1.residuals`)
```

Next, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.

```{r}
condo_resale.sp <- as_Spatial(condo_resale.res.sf)
condo_resale.sp
```

Use tmap package to display the distribution of the residuals on an interactive map.

```{r}
tmap_mode("view")
```

```{r}
tm_shape(mpsz_svy21)+
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.4) +
tm_shape(condo_resale.res.sf) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

\*Important: Switch back to plot mode before continuing.

```{r}
tmap_mode("plot")
```

The figure above reveals that there is sign of spatial autocorrelation.

To prove that our observation is indeed true, the Moran’s I test will be performed.

First, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.

```{r}
nb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)
summary(nb)
```

Next, *nb2listw()* of **spdep** package will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.

```{r}
nb_lw <- nb2listw(nb, style = 'W')
summary(nb_lw)
```

*lm.morantest()* of **spdep** package will be used to perform Moran’s I test for residual spatial autocorrelation

```{r}
lm.morantest(condo.mlr1, nb_lw)
```

The Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.

Since the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution.

# Building Hedonic Pricing Models using GWmodel

## Building Fixed Bandwidth GWR Model

### Computing fixed bandwidth

In the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.

There are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach agreement.

```{r}
bw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + 
                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                     FAMILY_FRIENDLY + FREEHOLD, 
                   data=condo_resale.sp, 
                   approach="CV", 
                   kernel="gaussian", 
                   adaptive=FALSE, 
                   longlat=FALSE)
```

### GWModel method - fixed bandwidth

```{r}
gwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + 
                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                         FAMILY_FRIENDLY + FREEHOLD, 
                       data=condo_resale.sp, 
                       bw=bw.fixed, 
                       kernel = 'gaussian', 
                       longlat = FALSE)
```

The output is saved in a list of class “gwrm”. The code below can be used to display the model output.

```{r}
gwr.fixed
```

The report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1.

## Building Adaptive Bandwidth GWR Model

In this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.

### Computing the adaptive bandwidth

Similar to the earlier section, we will first use *bw.gwr()* to determine the recommended data point to use.

The code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to **TRUE**.

```{r}
bw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + 
                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + 
                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + 
                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                      data=condo_resale.sp, 
                      approach="CV", 
                      kernel="gaussian", 
                      adaptive=TRUE, 
                      longlat=FALSE)
```

The result shows that the 30 is the recommended data points to be used.

### Constructing the adaptive bandwidth GWRmodel

To calibrate the gwr-based hedonic pricing model, use the adaptive bandwidth and Gaussian kernel as shown below.

```{r}
gwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + 
                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + 
                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                          data=condo_resale.sp, bw=bw.adaptive, 
                          kernel = 'gaussian', 
                          adaptive=TRUE, 
                          longlat = FALSE)
```

To display the model output,

```{r}
gwr.adaptive
```

## Visualising GWR Output

In addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:

-   Condition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.

-   Local R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.

-   Predicted: these are the estimated (or fitted) y values 3. computed by GWR.

-   Residuals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.

-   Coefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local colinearity.

They are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.

## Converting SDF into *sf* data.frame

To visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.

```{r}
condo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%
  st_transform(crs=3414)
```

```{r}
condo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)
condo_resale.sf.adaptive.svy21  
```

```{r}
gwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)
condo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))
```

Next, *glimpse()* is used to display the content of condo_resale.sf.adaptive sf data frame.

```{r}
glimpse(condo_resale.sf.adaptive)
```

## Visualising local R2

Creating an interactive point symbol map.

```{r}
tmap_mode("view")
tmap_options(check.and.fix = TRUE) 

tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "Local_R2",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))
```

```{r}
tmap_mode("plot")
```

## Visualising coefficient estimates

```{r}
tmap_mode("view")
tmap_options(check.and.fix = TRUE) 

AREA_SQM_SE <- tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_SE",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

AREA_SQM_TV <- tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_TV",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

tmap_arrange(AREA_SQM_SE, AREA_SQM_TV, 
             asp=1, ncol=2,
             sync = TRUE)
```

```{r}
tmap_mode("plot")
```

### By Planning Region

```{r}
tm_shape(mpsz_svy21[mpsz_svy21$REGION_N=="CENTRAL REGION", ]) +
  tm_polygons(id="REGION_N") +
tm_shape(condo_resale.sf.adaptive) + 
  tm_bubbles(col = "Local_R2",
           size = 0.15,
           border.col = "gray60",
           border.lwd = 1, id="REGION_N")
```
