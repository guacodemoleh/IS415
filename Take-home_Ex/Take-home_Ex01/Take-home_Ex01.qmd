---
title: "Take-home Exercise 1: Application of Spatial Point Patterns Analysis -- Geographical Distribution of Grab hailing services (Singapore)"
author: "Victoria Grace ANN"
execute: 
  warning: false
  eval: true
  echo: true
format:  
  html: 
    code-summary: "Show the code"
    toc-depth: 4
date: "22 January, 2024"
date-modified: "last-modified"
editor: visual
---

# Context

## Introduction

Human mobility, the movement of people in space and time, reflects the spatial-temporal characteristics of human behaviour ([Wang et al., 2021](https://www.mdpi.com/2220-9964/10/1/13)). With the advancement Information and Communication Technologies (ICT), pertinent through the ubiquitous use of smartphones, a large and growing volume of data relating to human mobility is available today. By using appropriate GIS analysis methods, such data are potentially useful in supporting smart-city planning and management.

## Data

In 2020, an interesting human mobility data set called [Grab Posisi](https://engineering.grab.com/grab-posisi) was released by GRAB, one of the largest shared taxi operators in Southeast Asia. One of the two data sets released is focusing on Singapore only.

In Singapore, relevant human mobility data can be extracted from [Land Transport Authority (LTA) DataMall](https://datamall.lta.gov.sg/content/datamall/en.html). In particular, two data sets related to human mobility are provided by the portal: [Passenger Volume by Origin Destination Train Stations](https://datamall.lta.gov.sg/content/datamall/en/search_datasets.html?searchText=Passenger%20Volume%20by%20Origin%20Destinat#:~:text=Passenger%20Volume%20by%20Origin%20Destination%20Train%20Stations) and [Passenger Volume by Origin Destination Bus Stops](https://datamall.lta.gov.sg/content/datamall/en/search_datasets.html?searchText=Passenger%20Volume%20by%20Origin%20Destinat#:~:text=Passenger%20Volume%20by%20Origin%20Destination%20Bus%20Stops).

## Limitation

A limitation of the LTA data sets is that their location is biased to either bus stops or MRT/LRT stations.

# Importing Packages

The following R packages are used for this assignment:

-   [**arrow**](https://arrow.apache.org/docs/r/), to read and write Parquet files (format in which data is in)

-   **lubridate**, to work with time-related data more easily

-   **tidyverse**, for importing, wrangling and visualising data

-   **tmap,** to create thematic maps

-   **sf**, for importing, managing and processing geospatial data

-   **spatstat**, for point pattern analysis

-   **raster**, reads, writes, manipulates, analyses and model of gridded spatial data (raster)

```{r}
pacman::p_load(arrow, lubridate, tidyverse, tmap, sf, spatstat, raster, readr,viridis)
```

# Data

# Geospatial Data

## Data preprocessing

***Master Plan 2019 Subzone Boundary***

First, we want to get a clear Singapore boundary layer.

Extracted from [data.gov.sg](https://beta.data.gov.sg/collections/1749/view), let's read the 2019 master plan subzone boundary layer.

```{r}
mpsz <- st_read("data/geospatial/master-plan-2019-subzone-boundary-no-sea-kml.kml")
summary(mpsz)
```

-   The dimension contains XYZ, meaning that `mpsz` contains 3D geometries

Convert `mpsz` to 2D geometry using *st_zm()* from **sf** and save the converted form as a shapefile.

```{r}
mpsz <- st_zm(mpsz, drop = TRUE) # Convert 3D geometries to 2D
```

Create a new column `SUBZONE_N` containing the subzone names.

```{r}
# create a new column 'SUBZONE_N' and extract subzone names from 'Dscrptn' field
mpsz <- mpsz %>%
  rowwise() %>%
  mutate(SUBZONE_N = str_extract(Description, "<th>SUBZONE_N</th> <td>(.*?)</td>")) %>%
  ungroup()

# remove HTML tags and 'SUBZONE_N' from 'SUBZONE_N' column
mpsz$SUBZONE_N <- str_remove_all(mpsz$SUBZONE_N, "<.*?>|SUBZONE_N")

# view the updated 'mpsz3414' dataframe
head(mpsz$SUBZONE_N)
```
Create a new column `PLN_AREA_N` containing the planning area names.
```{r}
# create a new column 'PLN_AREA_N' and extract subzone names from 'Dscrptn' field
mpsz <- mpsz %>%
  rowwise() %>%
  mutate(PLN_AREA_N = str_extract(Description, "<th>PLN_AREA_N</th> <td>(.*?)</td>")) %>%
  ungroup()

# remove HTML tags and 'PLN_AREA_N' from 'PLN_AREA_N' column
mpsz$PLN_AREA_N <- str_remove_all(mpsz$PLN_AREA_N, "<.*?>|PLN_AREA_N")

# view the updated 'mpsz3414' dataframe
head(mpsz$PLN_AREA_N)
```
```{r}
# Remove the 'Description' column using the $ operator
mpsz$Description <- NULL
head(mpsz)
```


```{r}
#| eval: false
st_write(mpsz, "data/geospatial/mpsz.shp")
```

```{r}
mpsz_sf <- st_read("data/geospatial/mpsz.shp")
```

Then transform the CRS from WGS84 to SVY21.

```{r}
mpsz3414 <- st_transform(mpsz_sf, 3414)
```


No commercial ride hailing services are available in the outer islands of Singapore. Let's identify them first.

![Outer Islands Subzones Viewed with QGIS](/img/outer_islands_qgis.jpg)

Filter out the outer islands.

```{r}
#| eval: false
outer_islands <- c("SEMAKAU", "SUDONG", "NORTH-EASTERN ISLANDS", "SOUTHERN GROUP")

# remove rows where 'SUBZONE_N' is in the list
mpsz3414 <- mpsz3414 %>%
  filter(!str_trim(SUBZONE_N) %in% str_trim(outer_islands))
```

Then dissolve all the inner subzone boundaries using *st_union()* (if necessary).

```{r}
sg_sf <- mpsz3414 %>% st_union()
plot(sg_sf)
```

***OSM Singapore Roads***

Get the roads layer from [OSM](geofabrik.de). Since the file is very large, it takes a long time to get the intersection between Singapore and roads (I took about 7 minutes to execute this step).

```{r}
#| eval: false
roads <- st_read(dsn="data/geospatial", layer="gis_osm_roads_free_1") %>%
  st_transform(crs=3414)

sg_roads <- st_intersection(roads,sg_sf)

# plot(sg_roads) #uncomment to run and check
```


Alternatively you may use QGIS to select the roads in Singapore and save the roads into a shape file. 

The following two code chunks can be uncommented if you are taking this approach.

```{r}
#| eval: false
sg_roads <- st_read(dsn= "data/geospatial", layer="sg_roads")
str(sg_roads)
```

Verify that `roads` are in the correct in CRS

```{r}
#| eval: false
st_crs(sg_roads) <- st_crs(3414)
st_crs(sg_roads)
```

-   The CRS ID is 3414 which is correct.


## Data Size Management

Before further data manipulation, save the files in **rds** format as the size of `roads3414` is very large.

Uncomment the following line to run them. I have commented them to prevent a rendering issue on my end.
```{r}
#| eval: false
write_rds(sg_roads,"data/geospatial/rds/sg_roads.rds")
```

Read the written roads file.
```{r}
sg_roads <- read_rds("data/geospatial/rds/sg_roads.rds")
```

# Aspatial Data

## Data preprocessing

Read all the Grab-Posisi using **arrow's** *read_parquet()* function to read the parquet files containing the ride trajectories.

Uncomment the following lines to run them. I have commented them to prevent a rendering issue on my end.
```{r}
#| eval: false
df0 <- read_parquet("data/aspatial/part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet")
df1 <- read_parquet("data/aspatial/part-00001-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet")
df2 <- read_parquet("data/aspatial/part-00002-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet")
df3 <- read_parquet("data/aspatial/part-00003-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet")
df4 <- read_parquet("data/aspatial/part-00004-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet")
df5 <- read_parquet("data/aspatial/part-00005-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet")
df6 <- read_parquet("data/aspatial/part-00006-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet")
df7 <- read_parquet("data/aspatial/part-00007-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet")
df8 <- read_parquet("data/aspatial/part-00008-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet")
df9 <- read_parquet("data/aspatial/part-00009-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet")
```

Then combine the rows using the *bindrows* function in the **dplyr** package embedded in the **tidyverse** package.

Uncomment the following lines to run them. I have commented them to prevent a rendering issue on my end.
```{r}
# |eval: false
#df <- bind_rows(df0, df1, df2, df3, df4, df5, df6, df7, df8, df9)
#head(df)
```

The observed `pingtimestamp` is not easily comprehensible, thus it needs to be amended to a proper timestamp.

Uncomment the following lines to run them. I have commented them to prevent a rendering issue on my end.
```{r}
# |eval: false
#df$pingtimestamp <- as_datetime(df$pingtimestamp) ## $ to overwrite the variable in df
#head(df$pingtimestamp)
```

The data can be further segmented to two groups:

-   `origin_df` representing the starting locations of trips taken

-   `dest_df` representing the end locations of trips taken

***Starting Locations***
Uncomment the following lines to run them. I have commented them to prevent a rendering issue on my end.
```{r}
# |eval: false
#origin_df <- df %>%
#  group_by(trj_id) %>%
#  arrange(pingtimestamp) %>% 
#  filter(row_number()==1) %>% 
#  mutate(weekday = wday(pingtimestamp, 
#                        label=TRUE,
#                        abbr=TRUE), 
#         start_hr = factor(hour(pingtimestamp)), 
#         day = factor(mday(pingtimestamp)))
```

***End Locations***

```{r}
# |eval: false
#dest_df <- df %>%
#  group_by(trj_id) %>%
#  arrange(desc(pingtimestamp)) %>% 
#  filter(row_number()==1) %>% 
#  mutate(weekday = wday(pingtimestamp, 
#                        label=TRUE,
#                        abbr=TRUE), 
#       end_hr = factor(hour(pingtimestamp)), 
#         day = factor(mday(pingtimestamp)))
```

## Data Size Management

Before further data manipulation, save the files in **rds** format as the size of the data frames are very large. Running the whole tibble data frame will not be practical and the processing time will be very long.

Uncomment the following lines to run them. I have commented them to prevent a rendering issue on my end.
```{r}
# |eval: false
#write_rds(origin_df,"data/aspatial/rds/origin_df.rds")
#write_rds(dest_df,"data/aspatial/rds/dest_df.rds")
```

```{r}
origin_df <- read_rds("data/aspatial/rds/origin_df.rds")
dest_df <- read_rds("data/aspatial/rds/dest_df.rds")
```

## Further Observation

Inspect the fields in `origin_df` and `dest_df`.

```{r}
list(origin_df)
list(dest_df)
```

## Creating a Simple Feature Data Frame from an Aspatial Data Frame

Convert the data frames into simple features data frame such that the locations can be plotted.

## Locations {.tabset}

### ***Starting Locations***

```{r}
# |eval: false
origin_sf <- origin_df %>% 
  st_as_sf(coords=c("rawlng","rawlat"),
           crs=4326) %>%
  st_transform(crs = 3414)

```


### ***End Locations***

```{r}
# |eval: false
dest_sf <- dest_df %>% 
  st_as_sf(coords=c("rawlng","rawlat"),
           crs=4326) %>%
  st_transform(crs = 3414)
```
##  {.unnumbered}

# Preparation for Spatial Point Patterns Analysis

## Converting sf Format into spatstat's ppp Format

Use as.ppp() of ***spatstat*** to convert the sf object ppp format. 


***Starting Locations***

```{r}
# |eval: false
origin_ppp <- as.ppp(st_coordinates(origin_sf), st_bbox(origin_sf))
plot(origin_ppp)
```

***Ending Locations***

```{r}
# |eval: false
dest_ppp <- as.ppp(st_coordinates(dest_sf), st_bbox(dest_sf))
plot(dest_ppp)
```

Look at summary statistics.

***Starting Locations***

```{r}
summary(origin_ppp)
```

***Ending Locations***

```{r}
summary(dest_ppp)
```

```{r}
any(duplicated(origin_ppp))
any(duplicated(dest_ppp))
```

-   With no duplicated starting locations nor ending locations, we can proceed to set up for our spatial point patterns analysis.

## Creating *owin* object

```{r}
# |eval: false
sg_owin <- as.owin(sg_sf)
plot(sg_owin)
```

## Combining point events object and *owin* object

Extract points that are located within Singapore

***Starting Locations***

```{r}
originSG_ppp = origin_ppp[sg_owin]
```

***Ending Locations***

```{r}
destSG_ppp = dest_ppp[sg_owin]
```

The output object contains the combination of the point and polygon feature into one ppp object class. 

***Starting Locations***

```{r}
summary(originSG_ppp)
```

***Ending Locations***

```{r}
summary(destSG_ppp)
```

Plot the before and after to compare the outputs
***Starting Locations***

```{r}
# |eval: false
par(mfrow=c(1,2))
par(mar = c(3,3,2,1))
plot(origin_ppp)
plot(originSG_ppp)
```

***Ending Locations***

```{r}
# |eval: false
par(mfrow=c(1,2))
par(mar = c(3,3,2,1))
plot(dest_ppp)
plot(destSG_ppp)
```

# Exploratory Data Analysis
From the raster images, it is difficult to determine which parts of Singapore had higher demand for pick-up and drop-off.

```{r}
joined_origin <- st_join(origin_sf, mpsz3414)

joined_origin <- joined_origin[, !names(joined_origin) %in% "geometry"]

head(joined_origin)



```
```{r}
joined_dest <- st_join(dest_sf, mpsz3414)
head(joined_dest)
```


**Starting Locations**
```{r}
downtown_core <- mpsz3414[mpsz3414$PLN_AREA_N == 'DOWNTOWN CORE', ]

roads_downtown_core <- sg_roads[st_intersection(sg_roads, downtown_core), ]

origin_downtown_core <- joined_origin[st_intersection(joined_origin, downtown_core), ]


tmap_mode("view")

map  <-  
  tm_basemap("OpenStreetMap")+
    tm_shape(downtown_core) +
      tm_borders(lwd=0.5) +
    tm_shape(roads_downtown_core) +
      tm_lines() 
    tm_shape(origin_downtown_core) +
      tm_dots()
```



To gain a better initial sensing, a choropleth map of the respective locations can be plotted.

**Starting Locations**
```{r}
origin_prop <- tm_shape(mpsz_sf) +
  tm_fill("prop_functional",
          n=10,
          title="Proportion",
          style="equal",
          palette="Blues") +
  tm_borders(lwd=0.2,
             alpha=1) +
  tm_layout(main.title = "Distribution of Pick-up Locations",
            legend.outside=FALSE,
            main.title.size=1)
```

**Ending Locations***
```{r}
dest_prop <- tm_shape(mpsz_sf) +
  tm_fill("prop_functional",
          n=10,
          title="Proportion",
          style="equal",
          palette="Blues") +
  tm_borders(lwd=0.2,
             alpha=1) +
  tm_layout(main.title = "Distribution of Pick-up Locations",
            legend.outside=FALSE,
            main.title.size=1)
```


# First-order Spatial Point Patterns Analysis



## Computing Kernel Density Estimation
