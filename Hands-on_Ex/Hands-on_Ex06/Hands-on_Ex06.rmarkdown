---
title: "Hands-on Exercise 6: Global and Local Measures of Spatial Autocorrelation"
author: "Victoria Grace ANN"
execute: 
  warning: false
date: "9 February, 2024"
date-modified: "last-modified"
---


These exercises train on the collection of geospatial statistical methods specially designed for measuring global and local spatial association.

These spatial statistics are well suited for: - detecting clusters or outliers - identifying hot spot or cold spot areas - assessing the assumptions of stationarity - identifying distances beyond which no discernible association obtains.

# Content

1.  What is Spatial Autocorrelation - Measures of Global Spatial Autocorrelation - Measures of Global High/Low Clustering

2.  Introducing Localised Geospatial Analysis - Local Indicators of Spatial Association (LISA)

3.  Cluster and Outlier Analysis - Local Moran and Local Geary - Moran scatterplot - LISA Cluster Map

4.  Hot Spot and Cold Spot Areas Analysis - Getis and Ord's G-statistics

5.  Case Studies

# A. Global Measures of Spatial Autocorrelation

## Overview

In Section A, we are learning how to compute Global and Local Measure of SPatial Autocorrelation (GSLA) by using the **spdep** package. The aim of this exercise is to:

-   import geospatial data using appropriate function(s) of **sf** package,

-   import csv file using appropriate function of **readr** package,

-   perform relational join using appropriate join function of **dplyr** package,

-   compute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of **spdep** package,

    -   plot Moran scatterplot,

    -   compute and plot spatial correlogram using appropriate function of **spdep** package

-   compute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions **spdep** package

-   compute Getis-Ord's Gi-statistics for detecting hot spot and/or cold spot area by using appropriate functions of **spdep** package, and

-   to visualise the analysis output by using tmap package.

# Getting Started

## Asking ourselves

Policymakers need to verify if development has been evenly distributed or implemented within a county or province. Thus, this study involves the application of appropriate spatial statistical methods if the development is evenly distributed geographically.

If the answer to that is **no**, then we should observe if there is the presence of spatial clustering. If the answer to this question is **yes**, then we should check where are these clusters.

We are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Province, the People's Republic of China.

## The Study Area and Data

Two data sets will be used in this hands-on exercise:

-   Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.

-   Hunan_2012.csv: This csv file contains selected Hunanâ€™s local development indicators in 2012.

## Setting the Analytical Tools

Before starting, ensure that **spdep**, **sf**, **tmap** and **tidyverse** packages of R are installed.

-   sf is use for importing and handling geospatial data in R,

-   tidyverse is mainly use for wrangling attribute data in R,

-   spdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and

-   tmap will be used to prepare cartographic quality chropleth map.


```{r}
pacman::p_load(sf, spdep, tmap, tidyverse)
```


# Getting the Data into R Environment

This section focuses on bringing geospatial data and its associated table of attributes in the R environment. The grospatial data is in ESRI shapefile format and the attribute table is in csv format.

## Importing shapefiles

Use *st_read()* of the **sf** package to import the Hunan shapefile.


```{r}
hunan <- st_read(dsn="data/geospatial", layer="Hunan")
```


## Importing csv

Next, import the csv file by using *read_csv()* of **readr()**.


```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```


## Performing relational joins

Check the column headers in the csv file.


```{r}
names(hunan2012)
```


Perform the relational join.


```{r}
hunan <- left_join(hunan,hunan2012) %>%
  select(1:4, 7, 15)
```


-   The left_join() function from the **dplyr** package is used to combine two datasets, *hunan* and *hunan2012*, based on common columns, i.e.`County` and `GDPPC` . It keeps all the rows from *hunan* and adds matching rows from *hunan2012*. The result is a new dataset that includes information from both datasets.
-   The pipe operator, *%\>%*, takes the result from the *left_join()* step and passes it as the first argument to the next step.
-   *select(1:4, 7, 15)*\` chooses columns 1 to 4, column 7 and column 15.
-   The output is a new dataframe containing the abovementioned columns

## Visualising Regional Development Indicator

Prepare a basemap and choropleth map showing the distribution of GDPPC 2012 using *qtm()* of **tmap** package


```{r}
equal <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal interval classification")

quantile <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal quantile classification")

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```


# Global Spatial Autocorrelation

Before computing global spatial autocorrelation statistics, spatial weights of the study area have to be contrusted first. The spatial weights are used to define the neighbourhood relationships between the geographical units, such as counties.

In the **spdep** package, *poly2nb* calculates contiguity weight matrices for a study area and determines which regions are adjacent to each other based on their shared boundaries. This function creates a list of neighbouring regions based on the regions' shared boundaries. By default, the Queen criteria determines the first-order neighbours as the `queen` argument is set to TRUE.

Weights are stored in a matrix.


```{r}
wm_q <- poly2nb(hunan, queen=TRUE)
summary(wm_q)
```


-   There are 88 area units in Hunan, where the most connected area unit has 11 neighbours.

## Row-standardised weight matrix

Next, equal weights are assigned to each neighbouring polygon. The weight will be evenly assigned using 1/nNeighbours to each county, then summing up the weighted income values.

-   Despite the intuitiveness, polygons along the edges of the study area will base their lagged on fewer polygons and there may be an over- or under-estimation of the spatial autocorrelation.

For this exercise, the style="W" will be used to achieve the aim of using equal weights.


```{r}
rswm_q <- nb2listw(wm_q, 
                   style="W", 
                   zero.policy = TRUE)
rswm_q
```


The input of *nb2listw()* must be an object of class neighbourhood, i.e. **nb**.

*style*

-   Takes in values:

    -   B - basic binary

    -   W - row-standardised, i.e. sums over all links to n

    -   C - global-standardised, i.e. sums over all links to n

    -   U - proportion of C over the number of neighbours, i.e. sums over all links to unity

    -   S - the variance-stabilising code scheme, i.e. sums over all links to n

*zero policy*

-   When it is set to TRUE, weight vectors of zero length are inserted for regions without neighbours inthe neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row,  t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.

## Global Spatial AUtocorrelation: Moran's I
This section performs Moran's I statistics using *moran.test()* of **spdep**

### Moran's I Test



