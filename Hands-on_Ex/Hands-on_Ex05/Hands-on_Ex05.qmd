---
title: "Hands-on Exercise 5 "
author: "Victoria Grace ANN"
execute: 
  warning: false
  eval: true
  echo: true
format:  
  html: 
    code-summary: "Show the code"
    toc-depth: 4
date: "2 February, 2024"
date-modified: "last-modified"
editor: visual
---

These exercises train on the collection of geospatial statistical methods specially designed for measuring global and local spatial association.

These spatial statistics are well suited for: - detecting clusters or outliers - identifying hot spot or cold spot areas - assessing the assumptions of stationarity - identifying distances beyond which no discernible association obtains.

# Content

1.  What is Spatial Autocorrelation - Measures of Global Spatial Autocorrelation - Measures of Global High/Low Clustering

2.  Introducing Localised Geospatial Analysis - Local Indicators of Spatial Association (LISA)

3.  Cluster and Outlier Analysis - Local Moran and Local Geary - Moran scatterplot - LISA Cluster Map

4.  Hot Spot and Cold Spot Areas Analysis - Getis and Ord's G-statistics

5.  Case Studies

# A. Global Measures of Spatial Autocorrelation

## Overview

In Section A, we are learning how to compute Global and Local Measure of SPatial Autocorrelation (GSLA) by using the **spdep** package. The aim of this exercise is to:

-   import geospatial data using appropriate function(s) of **sf** package,

-   import csv file using appropriate function of **readr** package,

-   perform relational join using appropriate join function of **dplyr** package,

-   compute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of **spdep** package,

    -   plot Moran scatterplot,

    -   compute and plot spatial correlogram using appropriate function of **spdep** package

-   compute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions **spdep** package

-   compute Getis-Ord's Gi-statistics for detecting hot spot and/or cold spot area by using appropriate functions of **spdep** package, and

-   to visualise the analysis output by using tmap package.

# Getting Started

## Asking ourselves

Policymakers need to verify if development has been evenly distributed or implemented within a county or province. Thus, this study involves the application of appropriate spatial statistical methods if the development is evenly distributed geographically.

If the answer to that is **no**, then we should observe if there is the presence of spatial clustering. If the answer to this question is **yes**, then we should check where are these clusters.

We are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Province, the People's Republic of China.

## The Study Area and Data

Two data sets will be used in this hands-on exercise:

-   Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.

-   Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.

## Setting the Analytical Tools

Before starting, ensure that **spdep**, **sf**, **tmap** and **tidyverse** packages of R are installed.

-   sf is use for importing and handling geospatial data in R,

-   tidyverse is mainly use for wrangling attribute data in R,

-   spdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and

-   tmap will be used to prepare cartographic quality chropleth map.

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse)
```

# Getting the Data into R Environment

This section focuses on bringing geospatial data and its associated table of attributes in the R environment. The grospatial data is in ESRI shapefile format and the attribute table is in csv format.

## Importing shapefiles

Use *st_read()* of the **sf** package to import the Hunan shapefile.

```{r}
hunan <- st_read(dsn="data/geospatial", layer="Hunan")
```

## Importing csv

Next, import the csv file by using *read_csv()* of **readr()**.

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

## Performing relational joins

Check the column headers in the csv file.

```{r}
names(hunan2012)
```

Perform the relational join.

```{r}
hunan <- left_join(hunan,hunan2012) %>%
  select(1:4, 7, 15)
```

-   The left_join() function from the **dplyr** package is used to combine two datasets, *hunan* and *hunan2012*, based on common columns, i.e.`County` and `GDPPC` . It keeps all the rows from *hunan* and adds matching rows from *hunan2012*. The result is a new dataset that includes information from both datasets.
-   The pipe operator, *%\>%*, takes the result from the *left_join()* step and passes it as the first argument to the next step.
-   *select(1:4, 7, 15)*\` chooses columns 1 to 4, column 7 and column 15.
-   The output is a new dataframe containing the abovementioned columns

## Visualising Regional Development Indicator

Prepare a basemap and choropleth map showing the distribution of GDPPC 2012 using *qtm()* of **tmap** package

```{r}
equal <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal interval classification")

quantile <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal quantile classification")

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```

# Global Spatial Autocorrelation

Before computing global spatial autocorrelation statistics, spatial weights of the study area have to be contrusted first. The spatial weights are used to define the neighbourhood relationships between the geographical units, such as counties.

In the **spdep** package, *poly2nb* calculates contiguity weight matrices for a study area and determines which regions are adjacent to each other based on their shared boundaries. This function creates a list of neighbouring regions based on the regions' shared boundaries. By default, the Queen criteria determines the first-order neighbours as the `queen` argument is set to TRUE.

Weights are stored in a matrix.

```{r}
wm_q <- poly2nb(hunan, queen=TRUE)
summary(wm_q)
```

-   There are 88 area units in Hunan, where the most connected area unit has 11 neighbours.

## Row-standardised weight matrix

Next, equal weights are assigned to each neighbouring polygon. The weight will be evenly assigned using 1/nNeighbours to each county, then summing up the weighted income values.

-   Despite the intuitiveness, polygons along the edges of the study area will base their lagged on fewer polygons and there may be an over- or under-estimation of the spatial autocorrelation.

For this exercise, the style="W" will be used to achieve the aim of using equal weights.

```{r}
rswm_q <- nb2listw(wm_q, 
                   style="W", 
                   zero.policy = TRUE)
rswm_q
```

The input of *nb2listw()* must be an object of class neighbourhood, i.e. **nb**.

*style*

-   Takes in values:

    -   B - basic binary

    -   W - row-standardised, i.e. sums over all links to n

    -   C - global-standardised, i.e. sums over all links to n

    -   U - proportion of C over the number of neighbours, i.e. sums over all links to unity

    -   S - the variance-stabilising code scheme, i.e. sums over all links to n

*zero policy*

-   When it is set to TRUE, weight vectors of zero length are inserted for regions without neighbours inthe neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row, t(rep(0, length=length(neighbours))) %\*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.

## Global Spatial Autocorrelation: Moran's I

This section performs Moran's I statistics using *moran.test()* of **spdep**

### Moran's I Test

Moran's I is a statistic measuring the spatial autocorrelation of a variable across a set of spatial units. It quantifies the degree of similarity (\~+1) or dissimilarity (\~-1) between neighbouring observations. The greater the degree of similarity, there is more positive spatial autocorrelation.

```{r}
moran.test(hunan$GDPPC, 
           listw=rswm_q, 
           zero.policy = TRUE, 
           na.action=na.omit)
```

-   It can be inferred that there is a weak positive spatial autocorrelation in the variable `GDPPC`, where regions with similar values tend to be spatially clustered together.

### Monte Carlo Moran's I

Monte Carlo Moran's I extends this measure by conducting a randomisation procedure to determine the statistical significance of the observed spatial autocorrelation. Monte Carlo Moran's I is particularly useful when assessing whether the observed spatial autocorrelation is statistically significant or simply due to chance.

```{r}
set.seed(1234)
bperm= moran.mc(hunan$GDPPC, 
                listw=rswm_q, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm
```

-   Since p-value is 0.001, it is highly unlikely that the observed spatial autocorrelation occurred by chance, which further supports the alternative hypothesis of greater spatial correlation.
-   Using set.seed() is helpful for reproducibility. It sets a starting point, or seed, to generate the sequence of random numbers each time the seed value is used to run with the code.

### Visualising Monte Carlo Moran's I

```{r}
mean(bperm$res[1:999])
```

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
library(ggplot2)
```

```{r}
# Initialize the plot canvas
plot.new()

# Simulated Moran's I values stored in bperm$res
simulated_values <- bperm$res

# Create the histogram
hist(simulated_values, freq = TRUE, breaks = 20, xlab = "Simulated Moran's I")

# Add a vertical line at 0
abline(v = 0, col = "red")
```

-   Since the simulated values follow a normal distribution, it suggests that the simulated values follow a random pattern and there is no structured spatial autocorrelation present.

## Global Spatial Autocorrelation: Geary's

### Geary's C test

Geary's C statistic, also known as the Geary's coefficient or Geary's ratio, is a measure of spatial autocorrelation that quantifies the similarity or dissimilarity of neighboring observations in a dataset.

The formula for calculating Geary's C statistic is:

$$
C = (1 / (2 * W)) * sum((x_i - x_j)^2 / w_ij * s^2)
$$ Where:

-   C is the Geary's C statistic.

-   W is the sum of the weights between all neighboring pairs of observations.

-   x_i and x_j are the values of the variable being analyzed for observations i and j.

-   w_ij is the weight between observations i and j, which represents the spatial relationship or distance between them.

-   s\^2 is the sample variance of the variable being analyzed. Geary's C statistic ranges from 0 to 2, with the following interpretations:

-   C close to 0 indicates strong positive spatial autocorrelation, meaning neighboring observations are very similar.

<!-- -->

-   C close to 1 indicates no spatial autocorrelation, meaning neighboring observations are not more similar or dissimilar than expected by chance.

-   C close to 2 indicates strong negative spatial autocorrelation, meaning neighboring observations are very dissimilar.

    In practice, the observed Geary's C statistic is compared to the expected value under the null hypothesis of no spatial autocorrelation to assess the significance of spatial patterns in the data. Deviations from the expected value indicate the presence of spatial autocorrelation, either positive or negative, depending on the value of C.

Performing Geary's C test requires the use of **spdep**'s *geary.test()*

```{r}
geary.test(hunan$GDPPC, listw=rswm_q)
```

-   There is strong evidence of positive spatial autocorrelation in `GDPPC`.
-   The observed Geary C statistic significantly deviates from the expectation under the null hypothesis, indicating that neighbouring observationss are more similar than expected by chance alone.

### Computing Monte Carlo Geary's C

```{r}
set.seed(1234)
bperm=geary.mc(hunan$GDPPC, 
               listw=rswm_q, 
               nsim=999)
bperm
```

-   There is strong evidence to reject the null hypothesis of no spatial autocorrelation, i.e. p-value\<0.05.
-   Hence, there is a significant positive spatial autocorrelation present.

### Visualising Monte Carlo Geary's C

```{r}
mean(bperm$res[1:999])
```

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res, freq=TRUE, breaks=20, xlab="Simulated Geary c")
abline(v=1, col="red")  
```

## Spatial Correlogram

Spatial correlograms are ideal for examining spatial autocorrelation patterns in data or model residuals. They show how correlated are the pairs of spatial observations when the distance or lag between them increases. Such observations are plots of some index of autocorrelation (Moran's I or Geary's C) against distance. Though correlograms are not as fundamental as variograms, they are very useful as an exploratory and descriptive tool. For this purpose, correlograms provide richer information than variograms.

### Computing Moran's I correlogram

In the *sp.correlogram()* of the **spdep** package, we can compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in moran's I.

```{r}
MI_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="I", 
                          style="W")
plot(MI_corr)
```

The style argument controls how neighbouring relationships and weights are handled in calculating the spatial autocorrelation coefficients reported. For the style argument, it can take the values - W (weight matrix): USes spatial weights matrix W to calculate the spatial correlation coefficients and this is the default style value, - B (binary): Converts the spatial weights matrix W into a binary matrix (1s where spatially lagged, 0s elsewhere) before calculating the coefficients, - C (connectivity): Uses only the connectivity structure of W (ignoring weights) to calculate coefficients based on number of neighbours. - S (self): Like W but with the diagonal of the weight matrix set to 1 so that spatially lagged variable also includes the original observation.

The plotting output may not provide a complete interpretation as not all autocorrelation values are statistically significant. Hence it is important to examine the full analysis report by printing out the analysis results.

```{r}
print(MI_corr)
```

There is a general decrease in positive spatial autocorrelation from the first lag to the sixth lag.

There is significant spatial clustering at short distances up to the third lag, followed by dispersion at broader distances of the fifth and sixth lags.

### Computing Geary's C correlogram

```{r}
GC_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="C", 
                          style="W")
plot(GC_corr)
```

```{r}
print(GC_corr)
```

# Local Indicators of Spatial Association

Local Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. For instance if we are studying cancer rates among census tracts in a given city local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.

In this section, you will learn how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.

## Computing Local Moran's I

To compute local Moran’s I, the [localmoran()](https://r-spatial.github.io/spdep/reference/localmoran.html) function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.

The code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.

```{r}
fips <- order(hunan$County)
localMI <- localmoran(hunan$GDPPC, rswm_q)
head(localMI)
```

localmoran() function returns a matrix of values whose columns are:

-   Ii: the local Moran’s I statistics
-   E.Ii: the expectation of local moran statistic under the randomisation hypothesis
-   Var.Ii: the variance of local moran statistic under the randomisation hypothesis
-   Z.Ii:the standard deviate of local moran statistic
-   Pr(): the p-value of local moran statistic

List the content of the local Moran matrix derived by using *printCoefmat()*.

```{r}
printCoefmat(data.frame(
  localMI[fips,], 
  row.names=hunan$County[fips]),
  check.names=FALSE)
```

### Mapping the Local Moran's I and Values

Append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.

```{r}
hunan.localMI <- cbind(hunan,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

Use a choropleth to map out the values.

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

### Mapping Local Moran's I p-values

The choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.

The code chunks below produce a choropleth map of Moran’s I p-values by using functions of **tmap** package.

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)
```

### Map both local Moran's I values and p-values

```{r}
localMI.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

## Creating a LISA Cluster Map

The LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.

### Plotting Moran scatterplot

The Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.

The code chunk below plots the Moran scatterplot of GDPPC 2012 by using [moran.plot()](https://r-spatial.github.io/spdep/reference/moran.plot.html) of spdep.

```{r}
nci <- moran.plot(hunan$GDPPC, rswm_q,
                  labels=as.character(hunan$County), 
                  xlab="GDPPC 2012", 
                  ylab="Spatially Lag GDPPC 2012")
```

The top right quadrant belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. These are the high-high locations.

### Plotting Moran scatterplot with standardised variables

First we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.

```{r}
hunan$Z.GDPPC <- scale(hunan$GDPPC) %>% 
  as.vector 
```

The [as.vector()](https://www.rdocumentation.org/packages/pbdDMAT/versions/0.5-1/topics/as.vector) added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.

Now, we are ready to plot the Moran scatterplot again by using the code chunk below.

```{r}
nci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,
                   labels=as.character(hunan$County),
                   xlab="z-GDPPC 2012", 
                   ylab="Spatially Lag z-GDPPC 2012")
```

### Preparing LISA map classes

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
```

Derive the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.

```{r}
hunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)
DV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     
```

Centre the local Moran's around the mean.

```{r}
LM_I <- localMI[,1] - mean(localMI[,1])    
```

Then set a statistical significance level for the local Moran.

```{r}
signif <- 0.05       
```

These four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.

```{r}
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4      
```

Place non-significant local Moran in the category 0.

```{r}
quadrant[localMI[,5]>signif] <- 0
```

## Plotting LISA map

```{r}
hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
```

Plot the local and corresponding Moran's I p-values maps next to each other.

```{r}
gdppc <- qtm(hunan, "GDPPC")

hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)

tmap_arrange(gdppc, LISAmap, 
             asp=1, ncol=2)
```

## Hot Spot and Cold Spot Area Analysis

Localised spatial statistics are useful for detecting hot spot and cold spot areas.

The term 'hot spot' is to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).

### Getis and Ord's G-Statistics

Getis and Ord's G-statistics also detect spatial anomalies. It looks at neighbours within a defined proximity to identify where either high or low values cluster spatially.

The analysis consists of three steps: - Deriving spatial weight matrix - Computing Gi statistics - Mapping Gi statistics

### Deriving distance-baased weight matrix

A new set of neighbours have to be defined first. Though spatial autocorrelation considers units sharing common borders, Getis-Ord defines neighbours based on distances.

The two types of distance-based proximity matrix are: - fixed distance weight matrix, and - adaptive distance weight matrix

#### Deriving the centroid

Points are needded to associate with each polygon before making a connectivity graph. The coordinates need to be in a separate data frame.

We will use a mapping function which applies a given function to each element of a vector and returns a vector of the same length. The input vector will be the geometry column, `us.bound`, and the function will be *st_centroid()*. The **map_dbl** variation of the map will be used from the *purrr package*.

Here is how the longitude and latitude values can be accessed.

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])

latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

Then use cbind to put the coordinates together.

```{r}
coords <- cbind(longitude, latitude)
```

#### Determine the cut-off distance

Determine the upper limit for the distance bands by using the following steps: - Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep. - Convert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb(). - Return the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise. - Remove the list structure of the returned object by using unlist().

```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.

#### Computing fixed distance weight matrix

Compute the distance weight matrix by using *dnearneigh()*.

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

Use *nb2listw()* to convert the nb object into spatial weights object.

```{r}
wm62_lw <- nb2listw(wm_d62, style = 'B')
summary(wm62_lw)
```

### Computing adaptive distance weight matrix

A characteristic of fixed distance weight matrix is that denser settlement areas tend to have more neighbours, vice versa. Having many neighbours smoothens the neighbour relationship across more neighbours.

It is possible to control the number of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry.

```{r}
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

Convert nb object into spatial weights object.

```{r}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

## Computing Gi statistics

### Gi statistics using fixed distance

```{r}
fips <- order(hunan$County)
gi.fixed <- localG(hunan$GDPPC, wm62_lw)
gi.fixed
```

The output of *localG()* is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.

The Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.

Next, we will join the Gi values to their corresponding `hunan` sf data frame by using the code chunk below.

```{r}
hunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

The above code above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan\@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().

### Mapping Gi values with fixed distance weights

```{r}
gdppc <- qtm(hunan, "GDPPC")

Gimap <-tm_shape(hunan.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp=1, ncol=2)
```

### Gi statistics using adaptive distance

Compute the Gi values for GDPPPC2012 using an adaptive distance weight matrix.

```{r}
fips <- order(hunan$County)
gi.adaptive <- localG(hunan$GDPPC, knn_lw)
hunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

### Mapping Gi values with adaptive distance weights

```{r}
gdppc<- qtm(hunan, "GDPPC")

Gimap <- tm_shape(hunan.gi) + 
  tm_fill(col = "gstat_adaptive", 
          style = "pretty", 
          palette="-RdBu", 
          title = "local Gi") + 
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, 
             Gimap, 
             asp=1, 
             ncol=2)
```
